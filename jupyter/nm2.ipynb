{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "import marimo as mo\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import sympy as sm\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(\"assets/articles/notebooks\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def display_iframe(path: str):\n",
    "    # Read the saved Plotly HTML file\n",
    "    with open(path, \"r\") as f:\n",
    "        html_content = f.read()\n",
    "\n",
    "    # Display it in Jupyter Notebook\n",
    "    return mo.iframe(html_content, height=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Optimization, Newton's Method, & Profit Maximization: Part 2 - Constrained Optimization Theory\n",
    "<center> **Learn how to solve constrained optimization problems** </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> This article is the **2nd** in a 3 part series. In the <a href=\"/articles/nm1\" target=\"_blank\" rel=\"noopener noreferrer\">1st part</a>, we studied basic optimization theory. Now, in pt. 2, we will extend this theory to constrained optimization problems. Lastly, in <a href=\"/articles/nm3\" target=\"_blank\" rel=\"noopener noreferrer\">pt. 3</a>, we will apply the optimization theory covered, as well as econometric and economic theory, to solve a profit maximization problem\n",
    "\n",
    "Consider the following problem: You want to determine how much money to invest in specific financial instruments to maximize your return on investment. However, the problem of simply maximizing your return on investment is too broad and simple of an optimization question to ask. By virtue of the simplicity, the solution is to just invest all of your money in the financial instrument has the highest probability for the highest return. Clearly this is not a good investment strategy; so, how can we improve this? By putting constraints on the investment decisions, our choice variables. For example, we can specify constraints that, to name a couple, 1) limit the amount of financial risk we are willing to entertain (see [modern portfolio theory](https://en.wikipedia.org/wiki/Modern_portfolio_theory)) or 2) specify the amount of our portfolio to be allocated towards each category of financial instruments (equity, bonds, derivatives, etc.) — the possibilities are endless. Notice how this problem becomes significantly more tractable as we add constraints. Despite this simple example, it helps to capture a fundamental motivation of constrained optimization:\n",
    "\n",
    "> The essence of constrained optimization is to provide unconstrained optimization problems a sense of tractability and applicability to complex real world problems.\n",
    "\n",
    "\n",
    "Constrained optimization is defined as “the process of optimizing an objective function with respect to some variables in the presence of constraints on those variables.”[1] The process of adding constraints on the variables transforms an unconstrained and, perhaps, intractable optimization problem into one which can help model and solve a real world problem. However, the addition of constraints can turn a simple optimization problem into a problem that is no longer trivial. In this post, we will dive into some of the techniques that we can add to our toolbox to extend the unconstrained optimization theory, learned in part 1 of this series, to now solve constrained optimization problems.\n",
    "\n",
    "> In <a href=\"/articles/nm1\" target=\"_blank\" rel=\"noopener noreferrer\">part 1</a>, we covered basic optimization theory — including 1) setting up and solving a simple single variable optimization problem analytically, 2) iterative optimization schemes — namely, gradient descent & Newton’s Method, and 3) implementing Newton’s method by hand and in python for a multi-dimensional optimization problem. This article is designed to be accessible for those who are already familiar with the content covered in part 1.\n",
    "\n",
    "## Optimization Basics - Part 1 Recap\n",
    "\n",
    "A mathematical optimization problem can be formulated abstractly as such:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\mathbf{x}} \\quad& f(\\mathbf{x}), \\mathbf{x}=[x_1,x_2,\\dots,x_n]^T \\in \\mathbb{R}^n \\\\\n",
    "\\text{subject to} \\quad & g_j(\\mathbf{x}) \\le 0, j=1,2,\\dots,m \\\\\n",
    "& h_j(\\mathbf{x}) = 0, j=1,2,\\dots,r\n",
    "\\end{aligned}\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where we choose real values of the vector $\\mathbf{x}$ that minimize the objective function $f(\\mathbf{x})$ (or maximize -$f(\\mathbf{x})$) subject to the inequality constraints $g(x)$ and equality constraints $h(x)$. In part 1, we discussed how to solve these problems in the absence of $g(x)$ and $h(x)$ and now we will introduce these back into our optimization problem. First, let’s succinctly recap how to implement Newton’s method for unconstrained problems.\n",
    "\n",
    "Recall that we can approximate the first order necessary condition of a minimum using a Taylor Series expansion:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "0 = \\nabla f(\\mathbf{x}^*)=\\nabla f(\\mathbf{x}_k + \\Delta) = \\nabla f(\\mathbf{x}_k) + \\mathbf{H}(\\mathbf{x}_k)\\Delta\\Rightarrow \\Delta = -\\mathbf{H}^{-1}(\\mathbf{x}_k)\\nabla f(\\mathbf{x}_k)\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{H}(\\mathbf{x})$ and $\\nabla f(\\mathbf{x})$ denote the Hessian and gradient of $f(\\mathbf{x})$, respectively. Each iterative addition of delta, $\\Delta$, is an expected better approximation of the optimal values $\\mathbf{x}^*$. Thus, each iterative step using the NM can be represented as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k -\\mathbf{H}^{-1}(\\mathbf{x}_k)\\nabla f(\\mathbf{x}_k)\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We do this scheme until we reach convergence across one or more of the following criteria:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\text{Criteria 1: } \\lVert \\mathbf{x}_k - \\mathbf{x}_{k-1} \\rVert < \\epsilon_1 \\\\[6pt]\n",
    "&\\text{Criteria 2: } \\lvert f(\\mathbf{x}_k) - f(\\mathbf{x}_{k-1}) \\rvert < \\epsilon_2\n",
    "\\end{aligned}\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Putting this into python code, we make use of [SymPy](https://www.sympy.org/en/index.html) — a python library for symbolic mathematics — and create generalizable functions to compute the gradient, compute the Hessian, and implement Newton’s method for an n-dimensional function (see <a href=\"/articles/nm1\" target=\"_blank\" rel=\"noopener noreferrer\">part 1</a> for full recap) and, leveraging these functions, we can solve an unconstrained optimization problem as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# Functions constructed in Part 1\n",
    "\n",
    "\n",
    "def get_gradient(\n",
    "    function: sm.Expr,\n",
    "    symbols: list[sm.Symbol],\n",
    "    x0: dict[sm.Symbol, float],  # Add x0 as argument\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the gradient of a function at a given point.\n",
    "\n",
    "    Args:\n",
    "        function (sm.Expr): The function to calculate the gradient of.\n",
    "        symbols (list[sm.Symbol]): The symbols representing the variables in the function.\n",
    "        x0 (dict[sm.Symbol, float]): The point at which to calculate the gradient.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The gradient of the function at the given point.\n",
    "    \"\"\"\n",
    "    d1 = {}\n",
    "    gradient = np.array([])\n",
    "\n",
    "    for i in symbols:\n",
    "        d1[i] = sm.diff(function, i, 1).evalf(subs=x0)  # add evalf method\n",
    "        gradient = np.append(gradient, d1[i])\n",
    "\n",
    "    return gradient.astype(np.float64)  # Change data type to float\n",
    "\n",
    "\n",
    "def get_hessian(\n",
    "    function: sm.Expr,\n",
    "    symbols: list[sm.Symbol],\n",
    "    x0: dict[sm.Symbol, float],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the Hessian matrix of a function at a given point.\n",
    "\n",
    "    Args:\n",
    "    function (sm.Expr): The function for which the Hessian matrix is calculated.\n",
    "    symbols (list[sm.Symbol]): The list of symbols used in the function.\n",
    "    x0 (dict[sm.Symbol, float]): The point at which the Hessian matrix is evaluated.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The Hessian matrix of the function at the given point.\n",
    "    \"\"\"\n",
    "    d2 = {}\n",
    "    hessian = np.array([])\n",
    "\n",
    "    for i in symbols:\n",
    "        for j in symbols:\n",
    "            d2[f\"{i}{j}\"] = sm.diff(function, i, j).evalf(subs=x0)\n",
    "            hessian = np.append(hessian, d2[f\"{i}{j}\"])\n",
    "\n",
    "    hessian = np.array(np.array_split(hessian, len(symbols)))\n",
    "\n",
    "    return hessian.astype(np.float64)\n",
    "\n",
    "\n",
    "def newtons_method(\n",
    "    function: sm.Expr,\n",
    "    symbols: list[sm.Symbol],\n",
    "    x0: dict[sm.Symbol, float],\n",
    "    iterations: int = 100,\n",
    "    tolerance: float = 10e-5,\n",
    "    verbose: int = 1,\n",
    ") -> dict[sm.Symbol, float] or None:\n",
    "    \"\"\"\n",
    "    Perform Newton's method to find the solution to the optimization problem.\n",
    "\n",
    "    Args:\n",
    "        function (sm.Expr): The objective function to be optimized.\n",
    "        symbols (list[sm.Symbol]): The symbols used in the objective function.\n",
    "        x0 (dict[sm.Symbol, float]): The initial values for the symbols.\n",
    "        iterations (int, optional): The maximum number of iterations. Defaults to 100.\n",
    "        tolerance (float, optional): Threshold for determining convergence.\n",
    "        verbose (int, optional): Control verbosity of output. 0 is no output, 1 is full output.\n",
    "\n",
    "    Returns:\n",
    "        dict[sm.Symbol, float] or None: The solution to the optimization problem, or None if no solution is found.\n",
    "    \"\"\"\n",
    "\n",
    "    x_star = {}\n",
    "    x_star[0] = np.array(list(x0.values()))\n",
    "\n",
    "    if verbose != 0:\n",
    "        print(f\"Starting Values: {x_star[0]}\")\n",
    "\n",
    "    for i in range(iterations):\n",
    "        gradient = get_gradient(function, symbols, dict(zip(x0.keys(), x_star[i])))\n",
    "        hessian = get_hessian(function, symbols, dict(zip(x0.keys(), x_star[i])))\n",
    "\n",
    "        x_star[i + 1] = x_star[i].T - np.linalg.inv(hessian) @ gradient.T\n",
    "\n",
    "        if np.linalg.norm(x_star[i + 1] - x_star[i]) < tolerance:\n",
    "            solution = dict(zip(x0.keys(), [float(x) for x in x_star[i + 1]]))\n",
    "            if verbose != 0:\n",
    "                print(\n",
    "                    f\"\\nConvergence Achieved ({i+1} iterations): Solution = {solution}\"\n",
    "                )\n",
    "            break\n",
    "        else:\n",
    "            solution = None\n",
    "\n",
    "        if verbose != 0:\n",
    "            print(f\"Step {i+1}: {x_star[i+1]}\")\n",
    "\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unconstrained_rosenbrocks():\n",
    "    x, y = sm.symbols(\"x y\")\n",
    "    Gamma = [x, y]\n",
    "    objective = 100 * (y - x**2) ** 2 + (1 - x) ** 2  # Objective function\n",
    "    Gamma0 = {x: -1.2, y: 1}  # Initial Guess\n",
    "\n",
    "    return newtons_method(objective, Gamma, Gamma0)\n",
    "\n",
    "\n",
    "_ = unconstrained_rosenbrocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "If all of the material reviewed above feels extremely foreign, then I recommend taking a look at <a href=\"/articles/nm1\" target=\"_blank\" rel=\"noopener noreferrer\">part 1</a> for a full recap. Without further ado, let’s dive into implementing constraints in our optimization problems.\n",
    "\n",
    "## Solving Constrained Optimization Problems\n",
    "\n",
    "> Note: All of the following constrained optimization techniques can and should be incorporated w/ gradient descent algorithms when applicable!\n",
    "\n",
    "As we discussed above there are two possible constraints on an objective function — equality and inequality constraints. Note that there are varying methodologies out there for dealing with each type of constraint with varying pros and cons. See [2] for a further discussion of different methodologies. Nevertheless, we will hone our focus in on two methodologies, one for equality and one for inequality constraints, that I believe are robust in their performance, easy to grasp for newcomers, and easily integrated together into one cohesive problem.\n",
    "\n",
    "### Equality Constraints - The Langrangian\n",
    "\n",
    "First, we will address optimization problems with equality constraints in our optimization problem. That is, optimization problems that take the form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\mathbf{x}} \\quad& f(\\mathbf{x}), \\mathbf{x}=[x_1,x_2,\\dots,x_n]^T \\in \\mathbb{R}^n \\\\\n",
    "\\text{subject to} \\quad& h_j(\\mathbf{x}) = 0, j=1,2,\\dots,r\n",
    "\\end{aligned}\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Suppose we are working with the Rosenbrock’s Parabolic Valley, as in part 1, but now with the equality constraint that $x^2 - y = 2$:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\Gamma} \\quad& 100(y-x^2)^2+(1-x)^2, \\Gamma = \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\in \\mathbb{R}^2 \\\\\n",
    "\\text{subject to} \\quad& x^2-y =2 \\Leftrightarrow x^2-y-2=0\n",
    "\\end{aligned}\n",
    "\\tag{6}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Note that, for simplicity and consistency, the equality constraints should be written such that they are equal to zero. Now our optimization problem looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def eqc_rosenbrocks_viz_3d():\n",
    "    # Define the Rosenbrock function\n",
    "    def rosenbrock(x, y):\n",
    "        return 100 * (y - x**2) ** 2 + (1 - x) ** 2\n",
    "\n",
    "    # Create the grid\n",
    "    x = np.linspace(-4, 4, 100)\n",
    "    y = np.linspace(-4, 4, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = rosenbrock(X, Y)\n",
    "\n",
    "    # Create constraint curve points\n",
    "    x_constraint = np.linspace(-np.sqrt(6), np.sqrt(6), 500)\n",
    "    y_constraint = x_constraint**2 - 2\n",
    "    z_constraint = rosenbrock(x_constraint, y_constraint)\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add the Rosenbrock surface\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            z=Z,\n",
    "            colorscale=\"plasma\",\n",
    "            opacity=0.8,\n",
    "            name=\"Rosenbrocks Surface\",\n",
    "            colorbar=dict(x=-0.15),\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add the constraint curve\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=x_constraint,\n",
    "            y=y_constraint,\n",
    "            z=z_constraint,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"green\", width=5),\n",
    "            name=\"Constraint: y = x^2 - 2; feasible region\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add the unconstrained optimum point\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[1],\n",
    "            y=[1],\n",
    "            z=[rosenbrock(1, 1)],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"red\", symbol=\"cross\"),\n",
    "            name=\"Unconstrained Optimum (1,1)\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add the constrained optimum point\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[1],\n",
    "            y=[-1],\n",
    "            z=[rosenbrock(1, -1)],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"green\"),\n",
    "            name=\"Constrained Optimum (1,-1)\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title=\"Rosenbrocks Parabolic Valley with Equality Constraints\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\",\n",
    "            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),\n",
    "        ),\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    fig.write_image(\"data/eqc_rosenbrocks_viz_3d.webp\", format=\"webp\", scale=5)\n",
    "    fig.write_html(\"data/eqc_rosenbrocks_viz_3d.html\")\n",
    "\n",
    "\n",
    "eqc_rosenbrocks_viz_3d()\n",
    "mo.image(\"data/eqc_rosenbrocks_viz_3d.webp\", height=500).center()\n",
    "# display_iframe(\"data/eqc_rosenbrocks_viz_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "[View Interactive Plotly Graph](/articles/notebooks/data/eqc_rosenbrocks_viz_3d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def eqc_rosenbrocks_viz_contour():\n",
    "    # Define the Rosenbrock function\n",
    "    def rosenbrock(x, y):\n",
    "        return 100 * (y - x**2) ** 2 + (1 - x) ** 2\n",
    "\n",
    "    # Compute gradient\n",
    "    def grad_rosenbrock(x, y):\n",
    "        df_dx = -400 * x * (y - x**2) - 2 * (1 - x)\n",
    "        df_dy = 200 * (y - x**2)\n",
    "        return df_dx, df_dy\n",
    "\n",
    "    # Define the grid\n",
    "    x_vals = np.linspace(-4, 4, 100)\n",
    "    y_vals = np.linspace(-4, 4, 100)\n",
    "    X, Y = np.meshgrid(x_vals, y_vals)\n",
    "    Z = rosenbrock(X, Y)\n",
    "\n",
    "    # Compute gradients for quiver plot\n",
    "    dX, dY = grad_rosenbrock(X, Y)\n",
    "\n",
    "    # Define constraint: y = x^2 - 2\n",
    "    x_constraint = np.linspace(-np.sqrt(6), np.sqrt(6), 500)\n",
    "    y_constraint = x_constraint**2 - 2\n",
    "\n",
    "    # Plot contours of Rosenbrock function\n",
    "    plt.figure(dpi=125)\n",
    "    contour = plt.contour(X, Y, Z, levels=50, cmap=\"plasma\")\n",
    "    plt.colorbar(contour)\n",
    "\n",
    "    # Overlay gradient field\n",
    "    plt.quiver(X, Y, dX, dY, color=\"red\", alpha=0.6)\n",
    "\n",
    "    # Mark the optimization point (theoretical minimum at (1,1))\n",
    "    plt.scatter(\n",
    "        1,\n",
    "        1,\n",
    "        color=\"red\",\n",
    "        marker=\"x\",\n",
    "        s=100,\n",
    "        label=\"Unconstrained Optimum (1,1)\",\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        1,\n",
    "        -1,\n",
    "        color=\"green\",\n",
    "        marker=\"o\",\n",
    "        s=100,\n",
    "        label=\"Constrained Optimum (1,-1)\",\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    # Plot constraint curve\n",
    "    plt.plot(\n",
    "        x_constraint,\n",
    "        y_constraint,\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1,\n",
    "        label=\"Constraint: $y = x^2 - 2$; Feasible Region\",\n",
    "    )\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(\"Contour Representation\")\n",
    "    plt.legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.4))\n",
    "    plt.savefig(\n",
    "        \"data/eqc_rosenbrocks_viz_contour.webp\",\n",
    "        format=\"webp\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "\n",
    "eqc_rosenbrocks_viz_contour()\n",
    "mo.image(\"data/eqc_rosenbrocks_viz_contour.webp\", height=600).center()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {},
   "source": [
    "where the **feasible region** of the optimal values lie along the intersection of the equality constraint curve and our objective function above.\n",
    "\n",
    "Joseph-Louis Lagrange developed a method for incorporating an equality constraint directly into the objective function — creating the Lagrangian function — so that traditional approaches using first and second derivates can still be applied.[2][3] Formally, the Lagrangian function takes the following form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}\n",
    "(\\mathbf{x},\\Lambda) &= f(\\mathbf{x})+\\sum^r_{j=1}\\lambda_jh_j(\\mathbf{x}), \\\\\n",
    "\\mathbf{x}&=[x_1,x_2,\\dots,x_n] \\\\\n",
    "\\Lambda &= [ \\lambda_1, \\lambda_2, \\dots,\\lambda_r]\n",
    "\\end{aligned}\n",
    "\\tag{7}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $f(\\mathbf{x})$ and $h(\\mathbf({x})$ are the objective function and equality constraints, respectively. $\\Lambda$ are the Lagrange multipliers that correspond to each equality constraint $h_j$. The Lagrange multipliers are treated as new choice variables in the Lagrangian function. It just so happens that the necessary conditions for $\\mathbf{x}^*$ to be a minimum of the equality constrained problem is that $\\mathbf{x}^*$ corresponds to the stationarity points of the Lagrangian $(\\mathbf{x}^*, \\Lambda^*)$. That is,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{x_i}}(\\mathbf{x}^*, \\Lambda^*)=0, i=1,2,\\dots,n \\\\[8pt]\n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{\\lambda_i}}(\\mathbf{x}^*, \\Lambda^*)=0, i=1,2,\\dots,n\n",
    "\\end{aligned}\n",
    "\\tag{8}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "For our above example — eq. 6 — we can write our Lagrangian function as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\Gamma,\\lambda) = 100(y-x^2)^2+(1-x)^2+\\lambda(x^2-y-2)\n",
    "\\tag{9}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We can then solve this Lagrangian using Newton’s method (or gradient descent!), but now including the Lagrange multipliers as additional choice variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqc_rosenbrocks():\n",
    "    x, y, λ = sm.symbols(\"x y λ\")\n",
    "\n",
    "    lagrangian = 100 * (y - x**2) ** 2 + (1 - x) ** 2 + λ * (x**2 - y - 2)\n",
    "    Gamma = [x, y, λ]\n",
    "    Gamma0 = {x: -1.2, y: 1, λ: 1}\n",
    "\n",
    "    return newtons_method(lagrangian, Gamma, Gamma0)\n",
    "\n",
    "\n",
    "_ = eqc_rosenbrocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {},
   "source": [
    "One can easily verify that the solution satisfies our equality constraint. And there you have it! That wasn’t too bad, right? This method can be extended to add any number of equality constraints — just add another Lagrange multiplier. Let’s move on now to the incorporation of inequality constraints.\n",
    "\n",
    "### Inequality Constraints - The Logarithmic Barrier Function\n",
    "\n",
    "Now we will address optimization problems with inequality constraints in our optimization problem. That is, optimization problems that take the form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\mathbf{x}} \\quad& f(\\mathbf{x}), \\mathbf{x}=[x_1,x_2,\\dots,x_n]^T \\in \\mathbb{R}^n \\\\\n",
    "\\text{subject to} \\quad& g_j(\\mathbf{x}) \\le 0, j=1,2,\\dots,m\n",
    "\\end{aligned}\n",
    "\\tag{10}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Suppose, again, we are working with Rosenbrock’s Parabolic Valley but now with the inequality constraints $x \\le 0$ and $y \\ge 3$:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\Gamma} \\quad& 100(y-x^2)^2+(1-x)^2, \\Gamma = \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\in \\mathbb{R}^2 \\\\\n",
    "\\text{subject to} \\quad& x \\le 0, \\quad y \\ge 3\n",
    "\\end{aligned}\n",
    "\\tag{11}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Now our optimization problem looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def ineqc_rosenbrocks_viz_3d():\n",
    "    # Define the Rosenbrock function\n",
    "    def rosenbrock(x, y):\n",
    "        return 100 * (y - x**2) ** 2 + (1 - x) ** 2\n",
    "\n",
    "    # Create the grid\n",
    "    x = np.linspace(-4, 4, 100)\n",
    "    y = np.linspace(-4, 8, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = rosenbrock(X, Y)\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add the Rosenbrock surface\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            z=Z,\n",
    "            colorscale=\"plasma\",\n",
    "            opacity=0.8,\n",
    "            name=\"Rosenbrocks Parabolic Valley\",\n",
    "            colorbar=dict(x=-0.15),\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create constraint planes\n",
    "    # For x <= 0 constraint\n",
    "    yc = np.linspace(-4, 8, 50)\n",
    "    zc = np.linspace(0, np.max(Z), 50)\n",
    "    YC, ZC = np.meshgrid(yc, zc)\n",
    "    XC = np.zeros_like(YC)  # x = 0 plane\n",
    "\n",
    "    # For y >= 3 constraint\n",
    "    xc = np.linspace(-4, 4, 50)\n",
    "    zc = np.linspace(0, np.max(Z), 50)\n",
    "    XC2, ZC2 = np.meshgrid(xc, zc)\n",
    "    YC2 = 3 * np.ones_like(XC2)  # y = 3 plane\n",
    "\n",
    "    # Add constraint planes\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            x=XC,\n",
    "            y=YC,\n",
    "            z=ZC,\n",
    "            colorscale=[[0, \"black\"], [1, \"black\"]],\n",
    "            opacity=0.3,\n",
    "            name=\"Constraint: x ≤ 0\",\n",
    "            showscale=False,\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            x=XC2,\n",
    "            y=YC2,\n",
    "            z=ZC2,\n",
    "            colorscale=[[0, \"black\"], [1, \"black\"]],\n",
    "            opacity=0.6,\n",
    "            name=\"Constraint: y ≥ 3\",\n",
    "            showscale=False,\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add the unconstrained optimum point\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[1],\n",
    "            y=[1],\n",
    "            z=[rosenbrock(1, 1)],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"red\", symbol=\"cross\"),\n",
    "            name=\"Unconstrained Optimum (1,1)\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add the constrained optimum point (approximately at -1.73, 3)\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[-1.73],\n",
    "            y=[3],\n",
    "            z=[rosenbrock(-1.73, 3)],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=6, color=\"green\"),\n",
    "            name=\"Constrained Optimum (-1.73,3)\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Define box edges for feasible region\n",
    "    box_edges = [\n",
    "        [-4, 3, 0],\n",
    "        [-4, 3, np.max(Z)],\n",
    "        [0, 3, np.max(Z)],\n",
    "        [0, 3, 0],\n",
    "        [-4, 8, 0],\n",
    "        [-4, 8, np.max(Z)],\n",
    "        [0, 8, np.max(Z)],\n",
    "        [0, 8, 0],\n",
    "    ]\n",
    "    box_faces = [\n",
    "        (0, 1, 2, 3),\n",
    "        (4, 5, 6, 7),\n",
    "        (0, 1, 5, 4),\n",
    "        (2, 3, 7, 6),\n",
    "        (0, 3, 7, 4),\n",
    "        (1, 2, 6, 5),\n",
    "    ]\n",
    "\n",
    "    for i, face in enumerate(box_faces):\n",
    "        x = [box_edges[i][0] for i in face] + [box_edges[face[0]][0]]\n",
    "        y = [box_edges[i][1] for i in face] + [box_edges[face[0]][1]]\n",
    "        z = [box_edges[i][2] for i in face] + [box_edges[face[0]][2]]\n",
    "\n",
    "        if i == 0:\n",
    "            show_legend = True\n",
    "        else:\n",
    "            show_legend = False\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                z=z,\n",
    "                mode=\"lines\",\n",
    "                name=\"Feasible Region\",\n",
    "                line=dict(color=\"lightgreen\", width=4),\n",
    "                showlegend=show_legend,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title=\"Rosenbrocks Parabolic Valley with Inequality Constraints\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\",\n",
    "            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),\n",
    "        ),\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    fig.write_html(\"data/ineqc_rosenbrocks_viz_3d.html\")\n",
    "    fig.write_image(\"data/ineqc_rosenbrocks_viz_3d.webp\", format=\"webp\", scale=5)\n",
    "\n",
    "\n",
    "ineqc_rosenbrocks_viz_3d()\n",
    "mo.image(\"data/ineqc_rosenbrocks_viz_3d.webp\", height=500).center()\n",
    "# display_iframe(\"data/ineqc_rosenbrocks_viz_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {},
   "source": [
    "[View Interactive Plotly Graph](/articles/notebooks/data/ineqc_rosenbrocks_viz_3d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def ineqc_rosenbrocks_viz_contour():\n",
    "    # Define the Rosenbrock function\n",
    "    def rosenbrock(x, y):\n",
    "        return 100 * (y - x**2) ** 2 + (1 - x) ** 2\n",
    "\n",
    "    # Compute gradient\n",
    "    def grad_rosenbrock(x, y):\n",
    "        df_dx = -400 * x * (y - x**2) - 2 * (1 - x)\n",
    "        df_dy = 200 * (y - x**2)\n",
    "        return df_dx, df_dy\n",
    "\n",
    "    # Define the grid\n",
    "    x_vals = np.linspace(-4, 4, 100)\n",
    "    y_vals = np.linspace(-4, 8, 100)\n",
    "    X, Y = np.meshgrid(x_vals, y_vals)\n",
    "    Z = rosenbrock(X, Y)\n",
    "\n",
    "    # Compute gradients for quiver plot\n",
    "    dX, dY = grad_rosenbrock(X, Y)\n",
    "\n",
    "    # Plot contours of Rosenbrock function\n",
    "    plt.figure(dpi=125)\n",
    "    contour = plt.contour(X, Y, Z, levels=50, cmap=\"plasma\")\n",
    "    plt.colorbar(contour)\n",
    "\n",
    "    # Overlay gradient field\n",
    "    plt.quiver(X, Y, dX, dY, color=\"red\", alpha=0.6)\n",
    "\n",
    "    # Mark the optimization points\n",
    "    plt.scatter(\n",
    "        1,\n",
    "        1,\n",
    "        color=\"red\",\n",
    "        marker=\"x\",\n",
    "        s=100,\n",
    "        label=\"Unconstrained Optimum (1,1)\",\n",
    "        zorder=3,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        -1.73,\n",
    "        3,\n",
    "        color=\"green\",\n",
    "        marker=\"o\",\n",
    "        s=100,\n",
    "        label=\"Constrained Optimum (-1.73,3)\",\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    # Plot constraint lines\n",
    "    plt.axvline(\n",
    "        0, color=\"black\", linestyle=\"-\", linewidth=2, label=\"Constraint: $x \\leq 0$\"\n",
    "    )\n",
    "    plt.axhline(\n",
    "        3,\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=\"Constraint: $y \\geq 3$\",\n",
    "    )\n",
    "\n",
    "    # Shade infeasible regions in gray\n",
    "    plt.fill_betweenx(y_vals, 0, 4, color=\"gray\", alpha=0.5)  # Shade region where x > 0\n",
    "    plt.fill_between(x_vals, -4, 3, color=\"gray\", alpha=0.5)  # Shade region where y < 3\n",
    "\n",
    "    # Labels and legend\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(\"Contour Representation\")\n",
    "    plt.legend(loc=\"lower center\", bbox_to_anchor=(0.5, -0.4))\n",
    "    plt.savefig(\n",
    "        \"data/ineqc_rosenbrocks_viz_contour.webp\",\n",
    "        format=\"webp\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "\n",
    "ineqc_rosenbrocks_viz_contour()\n",
    "mo.image(\"data/ineqc_rosenbrocks_viz_contour.webp\", height=600).center()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {},
   "source": [
    "where the **feasible region** lies in the quadrant bounded by the constraints that is marked by the green box in the 3D plot or the unshaded region in the contour plot.\n",
    "\n",
    "Because these constraints do not have a strict equality, our ability to directly include them into the objective function is not as straightforward. However, we can get creative — what we can do is augment our objective function to include a “barrier” in the objective function that penalizes values of the solution that approach the bounds of the inequality constraints. These class of methods are known as “interior-point methods” or “barrier methods.”[4][5] Like the Lagrangian function, we can transform our original constrained optimization problem into an unconstrained optimization problem by incorporating barrier functions (the logarithmic barrier function in our case) that can be solved using traditional methods— thereby creating the **barrier function**. Formally, the logarithmic barrier function is characterized by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathcal{B}\n",
    "(\\mathbf{x},\\rho) &= f(\\mathbf{x})- \\rho\\sum^m_{j=1}\\log(c_j(\\mathbf{x})), \\\\\n",
    "\\mathbf{x}&=[x_1,x_2,\\dots,x_n] \\\\[6pt]\n",
    "c_j(\\mathbf{x}) &= \\begin{cases}\n",
    "g_j(\\mathbf{x}), & g_j(\\mathbf{x}) \\geq 0 \\\\\n",
    "-g_j(\\mathbf{x}), & g_j(\\mathbf{x}) < 0\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "\\tag{12}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\rho$ is a small positive scalar — known as the barrier parameter. As $\\rho \\rightarrow 0$, the solution of the barrier function $\\mathcal{B}(\\mathbf{X},\\rho)$ should converge to the solution of our original constrained optimization function. Note, the $c(x)$ states that depending on how we formulate our inequality constraints (greater than or less than zero) will dictate whether we use the negative or positive of that constraint. We know that $y=\\log(x)$ is undefined for $x \\le 0$, thus we need to formulate our constraint to always be $\\ge 0$.\n",
    "\n",
    "How exactly does the barrier method work, you may ask? To begin with, when using the barrier method, we must choose starting values that are in the feasible region. As the optimal values approach the “barrier” outlined by the constraint, this method relies on the fact that the logarithmic function approaches negative infinity as the value approaches zero, thereby penalizing the objective function value. As $\\rho \\rightarrow 0$, the penalization decreases (see figure directly below) and we converge to the solution. However, it is necessary to start with a sufficiently large $\\rho$ so that the penalization is large enough to prevent “jumping” out of the barriers. Therefore, the algorithm has one extra loop than Newton’s method alone — namely, we choose a starting value $\\rho$, optimize the barrier function using Newton’s method, then update $\\rho$ by slowly decreasing it ($\\rho \\rightarrow 0$), and repeat until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "outputs": [],
   "source": [
    "def logarithmic_barrier_function():\n",
    "    # Defining surface and axes\n",
    "    x = np.linspace(0.01, 20, 1000)\n",
    "    y = np.log(x)\n",
    "    x2 = np.linspace(0.000000000000000000001, 20, 1000)\n",
    "    y2 = 0.1 * np.log(x2)\n",
    "\n",
    "    fig = plt.figure(dpi=125)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.spines[\"left\"].set_position(\"zero\")\n",
    "    ax.spines[\"bottom\"].set_position(\"zero\")\n",
    "    ax.spines[\"right\"].set_color(\"none\")\n",
    "    ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "    ax.set_yticks([-4, -3, -2, -1, 1, 2, 3])\n",
    "    ax.set_xticks([2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
    "\n",
    "    ax.text(x=16, y=3.2, s=\"ρ = 1\")\n",
    "    ax.text(x=16, y=0.6, s=\"ρ = 0.1\")\n",
    "\n",
    "    # plot the function\n",
    "    plt.plot(x, y, \"r\")\n",
    "    plt.plot(x, y2, \"g\")\n",
    "\n",
    "    plt.savefig(\"data/logarithmic_barrier_function.webp\", format=\"webp\", dpi=300)\n",
    "\n",
    "\n",
    "logarithmic_barrier_function()\n",
    "mo.image(\"data/logarithmic_barrier_function.webp\", height=500).center()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {},
   "source": [
    "Revisiting our example above — eq. 11 — we can write our barrier function as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{B}\n",
    "(\\Gamma,\\rho)=100(y-x^2)^2+(1-x)^2-\\rho\\log((y-3)(-x))\n",
    "\\tag{13}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Recall that $\\log(a) + \\log(b) = \\log(ab)$ and our one constraint $x \\le 0 \\rightarrow -x \\ge 0$. We must then update our code to accommodate the barrier method algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrained_newtons_method(\n",
    "    function: sm.Expr,\n",
    "    symbols: list[sm.Symbol],\n",
    "    x0: dict[sm.Symbol, float],\n",
    "    rho_steps: int = 100,\n",
    "    discount_rate: float = 0.9,\n",
    "    newton_method_iterations: int = 100,\n",
    "    tolerance: float = 10e-5,\n",
    ") -> dict[sm.Symbol, float] | None:\n",
    "    \"\"\"\n",
    "    Performs constrained Newton's method to find the optimal solution of a function subject to constraints.\n",
    "\n",
    "    Args:\n",
    "        function (sm.Expr): The function to optimize.\n",
    "        symbols (list[sm.Symbol]): The symbols used in the function.\n",
    "        x0 (dict[sm.Symbol, float]): The initial values for the symbols.\n",
    "        rho_steps (int, optional): The number of steps to update rho. Defaults to 100.\n",
    "        discount_rate (float, optional): The scalar to discount rho by at each step. Default is 0.9.\n",
    "        newton_method_iterations (int, optional): The maximum number of iterations in Newton Method internal loop. Defaults to 100.\n",
    "        tolerance (float, optional): Threshold for determining convergence.\n",
    "\n",
    "    Returns:\n",
    "        dict[sm.Symbol, float] or None: The optimal solution if convergence is achieved, otherwise None.\n",
    "    \"\"\"\n",
    "\n",
    "    rho = list(x0.keys())[-1]\n",
    "    optimal_solutions = []\n",
    "    optimal_solutions.append(x0)\n",
    "\n",
    "    for step in range(rho_steps):\n",
    "        if step % 10 == 0:\n",
    "            print(\"\\n\" + \"===\" * 20)\n",
    "            print(f\"Step {step} w/ rho={optimal_solutions[step][rho]}\")\n",
    "            print(\"===\" * 20 + \"\\n\")\n",
    "            print(f\"Current solution: {optimal_solutions[step]}\")\n",
    "\n",
    "        function_eval = function.evalf(subs={rho: optimal_solutions[step][rho]})\n",
    "\n",
    "        values = optimal_solutions[step].copy()\n",
    "        del values[rho]\n",
    "\n",
    "        optimal_solution = newtons_method(\n",
    "            function_eval,\n",
    "            symbols[:-1],\n",
    "            values,\n",
    "            iterations=newton_method_iterations,\n",
    "            tolerance=tolerance,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        optimal_solutions.append(optimal_solution)\n",
    "\n",
    "        # Check for overall convergence\n",
    "        current_solution = np.array(\n",
    "            [v for k, v in optimal_solutions[step].items() if k != rho]\n",
    "        )\n",
    "        previous_solution = np.array(\n",
    "            [v for k, v in optimal_solutions[step - 1].items() if k != rho]\n",
    "        )\n",
    "        if np.linalg.norm(current_solution - previous_solution) < tolerance:\n",
    "            overall_solution = optimal_solutions[step]\n",
    "            del overall_solution[rho]\n",
    "            print(\n",
    "                f\"\\n Overall Convergence Achieved ({step} steps): Solution = {overall_solution}\\n\"\n",
    "            )\n",
    "            break\n",
    "        else:\n",
    "            overall_solution = None\n",
    "\n",
    "        # Update rho\n",
    "        optimal_solutions[step + 1][rho] = discount_rate * optimal_solutions[step][rho]\n",
    "\n",
    "    return overall_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {},
   "source": [
    "We can now solve the Barrier function with the code above (Note: Make sure starting values are in the feasible range of inequality constraints & you may have to increase the starting value of rho if you jump out of inequality constraints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ineqc_rosenbrocks():\n",
    "    x, y, ρ = sm.symbols(\"x y ρ\")\n",
    "\n",
    "    Barrier_objective = (\n",
    "        100 * (y - x**2) ** 2 + (1 - x) ** 2 - ρ * sm.log((-x) * (y - 3))\n",
    "    )\n",
    "    Gamma = [x, y, ρ]  # Function requires last symbol to be ρ!\n",
    "    Gamma0 = {x: -15, y: 15, ρ: 10}\n",
    "\n",
    "    return constrained_newtons_method(Barrier_objective, Gamma, Gamma0)\n",
    "\n",
    "\n",
    "_ = ineqc_rosenbrocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {},
   "source": [
    "Again, one can verify the solution satisfies the inequality constraints specified. And there you have it. We have now tackled inequality constraints in our optimization problems. To wrap up, let’s put everything together and move on to tackling constrained optimization problems with mixed constraints — which is simply the combination of what we have done above.\n",
    "\n",
    "### Putting it All Together\n",
    "\n",
    "Let’s now solve our optimization problem by combining both the equality and inequality constraints from above. That is, we want to solve an optimization of the form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\mathbf{x}} \\quad& f(\\mathbf{x}), \\mathbf{x}=[x_1,x_2,\\dots,x_n]^T \\in \\mathbb{R}^n \\\\\n",
    "\\text{subject to} \\quad & g_j(\\mathbf{x}) \\le 0, j=1,2,\\dots,m \\\\\n",
    "& h_j(\\mathbf{x}) = 0, j=1,2,\\dots,r\n",
    "\\end{aligned}\n",
    "\\tag{14}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "All we have to do is combine the Lagrangian and the Barrier functions into one function. Thus, we can create a generalizable function, call it O, for dealing with optimization problems that have both equality and inequality constraints:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathcal{O}\n",
    "(\\mathbf{x},\\Lambda,\\rho) &= f(\\mathbf{x}) + \\sum^r_{j=1}\\lambda_jh_j(\\mathbf{x})- \\rho\\sum^m_{j=1}\\log(c_j(\\mathbf{x})), \\\\\n",
    "\\mathbf{x}&=[x_1,x_2,\\dots,x_n] \\\\[6pt]\n",
    "\\Lambda &= [\\lambda_1,\\lambda_2,\\dots,\\lambda_r] \\\\[6pt]\n",
    "c_j(\\mathbf{x}) &= \\begin{cases}\n",
    "g_j(\\mathbf{x}), & g_j(\\mathbf{x}) \\geq 0 \\\\\n",
    "-g_j(\\mathbf{x}), & g_j(\\mathbf{x}) < 0\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "\\tag{15}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where, as before, $\\Lambda$ is the vector of Lagrange multipliers and $\\rho$ is the barrier parameter. Thus, combining our constrained (Eq. 6) and unconstrained problems from above (Eq. 11), we can formulate our mixed constrained optimization problem as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathcal{O}\n",
    "(\\Gamma,\\Lambda,\\rho) &= 100(y-x^2)^2+(1-x)^2+\\lambda(x^2-y-2)-\\rho \\times \\log((y-3)(-x))\n",
    "\\end{aligned}\n",
    "\\tag{16}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In python,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_rosenbrocks():\n",
    "    x, y, λ, ρ = sm.symbols(\"x y λ ρ\")\n",
    "\n",
    "    combined_objective = (\n",
    "        100 * (y - x**2) ** 2\n",
    "        + (1 - x) ** 2\n",
    "        + λ * (x**2 - y - 2)\n",
    "        - ρ * sm.log((-x) * (y - 3))\n",
    "    )\n",
    "    Gamma = [x, y, λ, ρ]  # Function requires last symbol to be ρ!\n",
    "    Gamma0 = {x: -15, y: 15, λ: 0, ρ: 10}\n",
    "\n",
    "    return constrained_newtons_method(combined_objective, Gamma, Gamma0)\n",
    "\n",
    "\n",
    "_ = combined_rosenbrocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pvdt",
   "metadata": {},
   "source": [
    "And we can again verify this solution satisfies our contraints!\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Phew. Take a deep breath — you earned it. Hopefully at this point you should have a much better understanding of the techniques to incorporate constraints into your optimization problems. We are still just brushing the surface of the different tools and techniques utilized in mathematical optimization.\n",
    "\n",
    "Stay tuned for part 3 of this series, the final part, where we will apply the optimization material learned thus far alongside econometric & economic theory to solve a profit maximization problem. It is my goal that part 3 will bring home everything we have covered and show a practical use case. As usual, I hope you have enjoyed reading this much as much I have enjoyed writing it!\n",
    "\n",
    "## References\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Constrained_optimization\n",
    "\n",
    "[2] Snyman, J. A., & Wilke, D. N. (2019). Practical mathematical optimization: Basic optimization theory and gradient-based algorithms (2nd ed.). Springer.\n",
    "\n",
    "[3] https://en.wikipedia.org/wiki/Lagrange_multiplier\n",
    "\n",
    "[4] https://en.wikipedia.org/wiki/Interior-point_method\n",
    "\n",
    "[5] https://en.wikipedia.org/wiki/Barrier_function\n",
    "\n",
    "<div style=\"text-align: center; font-size: 24px;\">❖❖❖</div>\n",
    "\n",
    "<center>\n",
    "Access all the code via this Marimo Notebook or my [GitHub Repo](https://github.com/jakepenzak/blog-posts)\n",
    "\n",
    "I appreciate you reading my post! My posts primarily explore real-world and theoretical applications of econometric and statistical/machine learning techniques, but also whatever I am currently interested in or learning 😁. At the end of the day, I write to learn! I hope to make complex topics slightly more accessible to all.\n",
    "</center>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
